{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "924afeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d224cbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Loading testing data...\n",
      "Loaded 117500 training samples and 117500 testing samples.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading training data...\")\n",
    "with open('archive/x_train.txt', 'r', encoding='utf-8') as f:\n",
    "    X_train_text = f.read().splitlines()\n",
    "\n",
    "with open('archive/y_train.txt', 'r', encoding='utf-8') as f:\n",
    "    y_train_labels = f.read().splitlines()\n",
    "\n",
    "print(\"Loading testing data...\")\n",
    "with open('archive/x_test.txt', 'r', encoding='utf-8') as f:\n",
    "    X_test_text = f.read().splitlines()\n",
    "\n",
    "with open('archive/y_test.txt', 'r', encoding='utf-8') as f:\n",
    "    y_test_labels = f.read().splitlines()\n",
    "\n",
    "print(f\"Loaded {len(X_train_text)} training samples and {len(X_test_text)} testing samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db7a07be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(analyzer='char', ngram_range=(1, 4))),\n",
    "    ('classifier', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b51ca3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training the model...\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining the model...\")\n",
    "model_pipeline.fit(X_train_text, y_train_labels)\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "500d76a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model\n",
      "\n",
      "Model Accuracy: 91.93%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating model\")\n",
    "predictions = model_pipeline.predict(X_test_text)\n",
    "accuracy = accuracy_score(y_test_labels, predictions)\n",
    "print(f\"\\nModel Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff7c37ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ace       1.00      0.98      0.99       500\n",
      "         afr       0.93      1.00      0.96       500\n",
      "         als       0.98      0.89      0.93       500\n",
      "         amh       1.00      0.99      0.99       500\n",
      "         ang       1.00      0.89      0.94       500\n",
      "         ara       0.86      0.99      0.92       500\n",
      "         arg       1.00      0.81      0.90       500\n",
      "         arz       0.99      0.86      0.92       500\n",
      "         asm       1.00      0.97      0.98       500\n",
      "         ast       0.80      0.96      0.88       500\n",
      "\n",
      "   micro avg       0.95      0.93      0.94      5000\n",
      "   macro avg       0.96      0.93      0.94      5000\n",
      "weighted avg       0.96      0.93      0.94      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "unique_labels = sorted(list(set(y_test_labels)))\n",
    "print(classification_report(y_test_labels, predictions, labels=unique_labels[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "648265df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing with custom input ---\n",
      "The text 'This is a test of the language detection system.' was identified as: eng\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Testing with custom input ---\")\n",
    "custom_text = [\"This is a test of the language detection system.\"]\n",
    "prediction = model_pipeline.predict(custom_text)\n",
    "print(f\"The text '{custom_text[0]}' was identified as: {prediction[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49935b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving model to language_detector.joblib...\n",
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "model_filename = 'language_detector.joblib'\n",
    "print(f\"\\nSaving model to {model_filename}...\")\n",
    "joblib.dump(model_pipeline, model_filename)\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89e88f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model...\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading pre-trained model...\")\n",
    "try:\n",
    "    loaded_model = joblib.load('language_detector.joblib')\n",
    "    print(\"Model loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Model file 'language_detector.joblib' not found.\")\n",
    "    print(\"Please run the training script first to create the model file.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9af9c2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 'This is a sentence written in English.' \n",
      "--> Predicted Language: eng\n",
      "Text: 'Wie viel kostet das?' \n",
      "--> Predicted Language: deu\n",
      "Text: 'Esta es una frase en español.' \n",
      "--> Predicted Language: spa\n",
      "Text: 'یہ اردو میں لکھا ہوا ایک جملہ ہے۔' \n",
      "--> Predicted Language: urd\n"
     ]
    }
   ],
   "source": [
    "def predict_language(text):\n",
    "    prediction = loaded_model.predict([text])\n",
    "    return prediction[0]\n",
    "\n",
    "text1 = \"This is a sentence written in English.\"\n",
    "text2 = \"Wie viel kostet das?\"\n",
    "text3 = \"Esta es una frase en español.\"\n",
    "text4 = \"یہ اردو میں لکھا ہوا ایک جملہ ہے۔\" \n",
    "\n",
    "print(f\"Text: '{text1}' \\n--> Predicted Language: {predict_language(text1)}\")\n",
    "print(f\"Text: '{text2}' \\n--> Predicted Language: {predict_language(text2)}\")\n",
    "print(f\"Text: '{text3}' \\n--> Predicted Language: {predict_language(text3)}\")\n",
    "print(f\"Text: '{text4}' \\n--> Predicted Language: {predict_language(text4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189f9abe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
